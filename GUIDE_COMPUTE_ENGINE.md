# üñ•Ô∏è Guide de Configuration - Google Cloud Compute Engine

Ce guide vous explique comment cr√©er et configurer une machine virtuelle sur Google Cloud Compute Engine pour tester et ex√©cuter le projet de traduction fran√ßais-wolof.

## üìä Sp√©cifications Recommand√©es

### üéØ Option 1 : Pour l'Inf√©rence (Traduction uniquement) - √âCONOMIQUE

**Utilisation :** Tester le traducteur, faire des traductions  
**Co√ªt estim√© :** ~$30-50/mois (selon utilisation)

#### Configuration Recommand√©e :

```
Type de machine : n1-standard-2 ou e2-standard-2
‚îú‚îÄ‚îÄ vCPU : 2
‚îú‚îÄ‚îÄ RAM : 7.5 Go (n1) ou 8 Go (e2)
‚îú‚îÄ‚îÄ GPU : Aucune (fonctionne sur CPU)
‚îú‚îÄ‚îÄ Disque : 50 Go SSD (Standard Persistent Disk)
‚îî‚îÄ‚îÄ OS : Ubuntu 22.04 LTS
```

**Avantages :**
- ‚úÖ Co√ªt r√©duit
- ‚úÖ Suffisant pour tester et utiliser le traducteur
- ‚úÖ Pas besoin de GPU
- ‚úÖ D√©marrage rapide

**Inconv√©nients :**
- ‚ö†Ô∏è Traductions plus lentes (quelques secondes par phrase)
- ‚ö†Ô∏è Ne convient pas pour l'entra√Ænement

---

### üöÄ Option 2 : Pour l'Entra√Ænement - RECOMMAND√â

**Utilisation :** Entra√Æner un mod√®le personnalis√©  
**Co√ªt estim√© :** ~$200-400/mois (selon utilisation)

#### Configuration Recommand√©e :

```
Type de machine : n1-standard-8 avec GPU
‚îú‚îÄ‚îÄ vCPU : 8
‚îú‚îÄ‚îÄ RAM : 30 Go
‚îú‚îÄ‚îÄ GPU : 1x NVIDIA T4 (16 Go VRAM)
‚îú‚îÄ‚îÄ Disque : 100 Go SSD (Standard Persistent Disk)
‚îî‚îÄ‚îÄ OS : Ubuntu 22.04 LTS avec CUDA
```

**Sp√©cifications d√©taill√©es :**
- **Machine Type :** `n1-standard-8`
- **GPU Type :** `nvidia-tesla-t4`
- **Nombre de GPU :** 1
- **Disque Boot :** 100 Go SSD
- **Disque Additionnel :** 50 Go pour les donn√©es (optionnel)

**Avantages :**
- ‚úÖ Entra√Ænement rapide (quelques heures au lieu de jours)
- ‚úÖ Peut g√©rer de gros datasets
- ‚úÖ Supporte l'entra√Ænement avec mixed precision (FP16)

**Inconv√©nients :**
- ‚ö†Ô∏è Co√ªt plus √©lev√©
- ‚ö†Ô∏è N√©cessite configuration CUDA

---

### üí™ Option 3 : Pour l'Entra√Ænement Intensif - HAUTE PERFORMANCE

**Utilisation :** Entra√Ænement de gros mod√®les, datasets volumineux  
**Co√ªt estim√© :** ~$500-1000/mois (selon utilisation)

#### Configuration Recommand√©e :

```
Type de machine : n1-standard-16 avec GPU
‚îú‚îÄ‚îÄ vCPU : 16
‚îú‚îÄ‚îÄ RAM : 60 Go
‚îú‚îÄ‚îÄ GPU : 1x NVIDIA V100 (32 Go VRAM) ou 2x NVIDIA T4
‚îú‚îÄ‚îÄ Disque : 200 Go SSD (Standard Persistent Disk)
‚îî‚îÄ‚îÄ OS : Ubuntu 22.04 LTS avec CUDA
```

**Sp√©cifications d√©taill√©es :**
- **Machine Type :** `n1-standard-16`
- **GPU Type :** `nvidia-tesla-v100` ou `nvidia-tesla-t4` (x2)
- **Nombre de GPU :** 1 ou 2
- **Disque Boot :** 200 Go SSD

---

## üõ†Ô∏è Instructions de Cr√©ation sur Google Cloud

### √âtape 1 : Cr√©er la Machine Virtuelle

#### Via la Console Web :

1. **Acc√©dez √† Compute Engine :**
   - Allez sur https://console.cloud.google.com
   - Naviguez vers **Compute Engine** > **VM instances**

2. **Cliquez sur "CREATE INSTANCE"**

3. **Configurez les param√®tres :**

   **Nom de l'instance :**
   ```
   wolof-translator-vm
   ```

   **R√©gion et Zone :**
   - Choisissez une r√©gion proche de vous
   - Exemple : `europe-west1-b` (Belgique) ou `us-central1-a` (Iowa)

   **Type de machine :**
   - Pour inf√©rence : `e2-standard-2` ou `n1-standard-2`
   - Pour entra√Ænement : `n1-standard-8`

   **GPU (uniquement pour entra√Ænement) :**
   - Cochez "Add GPU"
   - Type : `NVIDIA T4` ou `NVIDIA V100`
   - Nombre : 1

   **Disque Boot :**
   - Type : **SSD Persistent Disk**
   - Taille : 50 Go (inf√©rence) ou 100-200 Go (entra√Ænement)
   - Image : **Ubuntu 22.04 LTS**

   **Firewall :**
   - Cochez "Allow HTTP traffic"
   - Cochez "Allow HTTPS traffic"

4. **Cliquez sur "CREATE"**

#### Via gcloud CLI :

**Pour l'inf√©rence (sans GPU) :**
```bash
gcloud compute instances create wolof-translator-vm \
    --zone=europe-west1-b \
    --machine-type=e2-standard-2 \
    --image-family=ubuntu-2204-lts \
    --image-project=ubuntu-os-cloud \
    --boot-disk-size=50GB \
    --boot-disk-type=pd-standard \
    --tags=http-server,https-server
```

**Pour l'entra√Ænement (avec GPU) :**
```bash
gcloud compute instances create wolof-translator-vm \
    --zone=europe-west1-b \
    --machine-type=n1-standard-8 \
    --accelerator=type=nvidia-tesla-t4,count=1 \
    --image-family=ubuntu-2204-lts \
    --image-project=ubuntu-os-cloud \
    --boot-disk-size=100GB \
    --boot-disk-type=pd-ssd \
    --maintenance-policy=TERMINATE \
    --tags=http-server,https-server
```

‚ö†Ô∏è **Note importante :** Les GPU n√©cessitent une **quota sp√©ciale** sur Google Cloud. Vous devrez peut-√™tre demander une augmentation de quota.

---

### √âtape 2 : Se Connecter √† la Machine

#### Via SSH dans la Console Web :
1. Cliquez sur votre instance
2. Cliquez sur "SSH" (ouvre un terminal dans le navigateur)

#### Via gcloud CLI :
```bash
gcloud compute ssh wolof-translator-vm --zone=europe-west1-b
```

#### Via SSH classique :
```bash
ssh -i ~/.ssh/google_compute_engine votre-utilisateur@IP_EXTERNE
```

---

### √âtape 3 : Configuration Initiale (Ubuntu)

Une fois connect√©, ex√©cutez ces commandes :

```bash
# Mettre √† jour le syst√®me
sudo apt update && sudo apt upgrade -y

# Installer les outils de base
sudo apt install -y python3 python3-pip git curl wget

# Installer Python 3.10+ si n√©cessaire
sudo apt install -y software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa -y
sudo apt update
sudo apt install -y python3.10 python3.10-venv python3.10-dev

# V√©rifier la version
python3 --version  # Doit √™tre 3.8 ou sup√©rieur
```

---

### √âtape 4 : Installation de CUDA (UNIQUEMENT pour GPU)

Si vous avez une machine avec GPU, installez CUDA :

```bash
# Installer les d√©pendances
sudo apt install -y build-essential

# T√©l√©charger et installer CUDA 11.8 (compatible avec PyTorch)
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run

# Ajouter CUDA au PATH
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# Installer cuDNN (optionnel mais recommand√©)
# T√©l√©chargez depuis https://developer.nvidia.com/cudnn
# Suivez les instructions d'installation
```

**Alternative plus simple :** Utilisez l'image Deep Learning de Google Cloud qui inclut d√©j√† CUDA :
```bash
# Lors de la cr√©ation de la VM, utilisez :
--image-family=common-cu121 \
--image-project=ml-images
```

---

### √âtape 5 : Cloner et Installer le Projet

```bash
# Cloner le projet (remplacez par votre repo)
git clone https://github.com/votre-username/Wolof-NMT.git
cd Wolof-NMT

# Cr√©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer les d√©pendances
pip install --upgrade pip
pip install -r requirements.txt

# Pour GPU, installer PyTorch avec support CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

### √âtape 6 : Configuration

```bash
# Cr√©er le fichier .env
nano .env
```

Ajoutez :
```bash
MODEL_CHECKPOINT=facebook/nllb-200-distilled-600M
DATASET_NAME=galsenai/french-wolof-translation
```

Sauvegardez avec `Ctrl+O`, puis `Ctrl+X`.

---

### √âtape 7 : Tester l'Installation

```bash
# Test simple
python3 test_translator.py

# Ou utiliser le script de d√©marrage
python3 debuter.py
```

---

## üîß Configuration Avanc√©e

### V√©rifier la Disponibilit√© GPU

```bash
# Installer nvidia-smi
sudo apt install -y nvidia-utils-535

# V√©rifier
nvidia-smi
```

Vous devriez voir votre GPU list√© avec ses sp√©cifications.

### Optimiser les Performances

**Pour l'inf√©rence :**
```python
# Dans votre code, forcez l'utilisation du CPU si GPU non disponible
translator = FrenchWolofTranslator(
    model_checkpoint="facebook/nllb-200-distilled-600M",
    device="cpu"  # ou "cuda" si GPU disponible
)
```

**Pour l'entra√Ænement :**
- Utilisez `fp16=True` dans `TrainingConfig` (d√©j√† activ√© par d√©faut)
- Ajustez `per_device_train_batch_size` selon votre GPU

---

## üí∞ Estimation des Co√ªts

### Option 1 (Inf√©rence - e2-standard-2) :
- **Machine :** ~$0.067/heure = ~$50/mois (si utilis√© 24/7)
- **Disque :** ~$8/mois (50 Go SSD)
- **Total :** ~$58/mois

### Option 2 (Entra√Ænement - n1-standard-8 + T4) :
- **Machine :** ~$0.38/heure = ~$280/mois (si utilis√© 24/7)
- **GPU T4 :** ~$0.35/heure = ~$250/mois
- **Disque :** ~$17/mois (100 Go SSD)
- **Total :** ~$547/mois

‚ö†Ô∏è **Astuce :** Arr√™tez la machine quand vous ne l'utilisez pas pour √©conomiser !

```bash
# Arr√™ter la machine
gcloud compute instances stop wolof-translator-vm --zone=europe-west1-b

# Red√©marrer
gcloud compute instances start wolof-translator-vm --zone=europe-west1-b
```

---

## üö® Points Importants

### Quotas GPU

Les GPU n√©cessitent une **quota sp√©ciale** sur Google Cloud :
1. Allez dans **IAM & Admin** > **Quotas**
2. Filtrez par "NVIDIA T4" ou "NVIDIA V100"
3. Demandez une augmentation si n√©cessaire

### Firewall

Pour acc√©der √† votre application depuis l'ext√©rieur :
```bash
# Autoriser le port 8000 (exemple)
gcloud compute firewall-rules create allow-translator \
    --allow tcp:8000 \
    --source-ranges 0.0.0.0/0 \
    --description "Allow translator API"
```

### Sauvegarde

Cr√©ez des snapshots r√©guliers :
```bash
gcloud compute disks snapshot wolof-translator-vm \
    --snapshot-names wolof-translator-snapshot-$(date +%Y%m%d) \
    --zone=europe-west1-b
```

---

## üìã Checklist de D√©ploiement

- [ ] Machine cr√©√©e avec les bonnes sp√©cifications
- [ ] Connexion SSH fonctionnelle
- [ ] Python 3.8+ install√©
- [ ] CUDA install√© (si GPU)
- [ ] Projet clon√©
- [ ] D√©pendances install√©es
- [ ] Fichier .env configur√©
- [ ] Test r√©ussi avec `test_translator.py`
- [ ] GPU d√©tect√© (si applicable) avec `nvidia-smi`
- [ ] Firewall configur√© (si API externe)
- [ ] Snapshots configur√©s

---

## üÜò D√©pannage

### GPU non d√©tect√©
```bash
# V√©rifier les drivers NVIDIA
nvidia-smi

# Si erreur, installer les drivers
sudo apt install -y nvidia-driver-535
sudo reboot
```

### Erreur "CUDA out of memory"
- R√©duisez `per_device_train_batch_size` dans `config.py`
- Utilisez `gradient_accumulation_steps` pour simuler des batches plus grands

### Machine trop lente
- V√©rifiez l'utilisation CPU/RAM : `htop`
- V√©rifiez l'utilisation disque : `df -h`
- Consid√©rez une machine plus puissante

---

## üìö Ressources Utiles

- [Documentation Compute Engine](https://cloud.google.com/compute/docs)
- [Guide GPU sur GCP](https://cloud.google.com/compute/docs/gpus)
- [Prix Compute Engine](https://cloud.google.com/compute/pricing)
- [Quotas GCP](https://cloud.google.com/compute/quotas)

---

**Bon d√©ploiement ! üöÄ**

